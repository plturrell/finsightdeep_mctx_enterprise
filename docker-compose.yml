version: '3.8'

# MCTX Docker Compose Configuration
# Provides multiple deployment options:
# - NVIDIA GPU optimized version (for T4 GPUs)
# - Vercel-ready API deployment
# - Visualization server

services:
  # NVIDIA GPU version with T4 optimizations
  mctx-nvidia:
    build:
      context: .
      dockerfile: docker/Dockerfile.nvidia
    image: mctx-nvidia:latest
    container_name: mctx-nvidia
    volumes:
      - ./examples:/app/examples
      - ./mctx_output:/app/mctx_output
    ports:
      - "8050:8050"  # Visualization server
      - "8000:8000"  # API server
    environment:
      - JAX_PLATFORM_NAME=gpu
      - MCTX_ENABLE_T4_OPTIMIZATIONS=1
      - XLA_PYTHON_CLIENT_ALLOCATOR=platform
      - LOG_LEVEL=INFO
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    restart: unless-stopped

  # API service version (Vercel-compatible)
  mctx-api:
    build:
      context: .
      dockerfile: docker/Dockerfile.vercel
    image: mctx-api:latest
    container_name: mctx-api
    ports:
      - "3000:3000"  # API server
    environment:
      - JAX_PLATFORM_NAME=cpu
      - PORT=3000
      - LOG_LEVEL=INFO
      - MAX_BATCH_SIZE=8
      - MAX_NUM_SIMULATIONS=50
    command: ["api"]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/info"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    
  # Visualization server
  mctx-vis:
    build:
      context: .
      dockerfile: docker/Dockerfile.nvidia
    image: mctx-nvidia:latest
    container_name: mctx-vis
    ports:
      - "8050:8050"  # Visualization server
    volumes:
      - ./examples:/app/examples
      - ./mctx_output:/app/mctx_output
    environment:
      - JAX_PLATFORM_NAME=cpu
    command: ["visualize"]
    restart: unless-stopped
    
  # Existing services
  # Basic API service (CPU-only development version)
  api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8001:8000"  # Changed port to avoid conflict
    volumes:
      - ./api:/app/api
    environment:
      - DEBUG=True
      - LOG_LEVEL=INFO
      - JAX_PLATFORM=cpu
      - MAX_BATCH_SIZE=64
      - MAX_NUM_SIMULATIONS=500
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/mcts/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
  
  # Simple frontend for development
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    depends_on:
      - api
    environment:
      - REACT_APP_API_BASE_URL=http://localhost:8001/api/v1
    restart: unless-stopped
    
  # Basic monitoring setup
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    restart: unless-stopped
    
  grafana:
    image: grafana/grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    restart: unless-stopped

volumes:
  grafana_data: